{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      "[[ 3.5  3.9  4.3  4.8  5.3]\n",
      " [ 3.1  3.5  4.8  5.3  5.9]\n",
      " [ 2.8  2.5 10.   5.9  6.6]\n",
      " [ 2.5 10.  10.  10.   7.3]\n",
      " [ 2.3  9.  10.   9.   8.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Grid world size\n",
    "grid_size = 5\n",
    "# Initialize value function\n",
    "V = np.zeros((grid_size, grid_size))\n",
    "V_new = np.zeros_like(V)\n",
    "# Reward for each state\n",
    "R = np.zeros((grid_size, grid_size))\n",
    "# Terminal states\n",
    "R[3, 2] = 1\n",
    "# Forbidden states\n",
    "R[1, 1] = R[1, 2] = R[2, 2] = R[3, 1] = R[3, 3] = R[4, 1] = -1\n",
    "# Discount factor\n",
    "gamma = 0.9\n",
    "\n",
    "# Define a deterministic policy\n",
    "def policy(state):\n",
    "    x, y = state\n",
    "    if y == 0 and x != 0:\n",
    "        return 'up'\n",
    "    if x == 0 and y != 4:\n",
    "        return 'right'\n",
    "    if y == 4 and x != 4:\n",
    "        return 'down'\n",
    "    if state in [(1,1), (4,2)]:\n",
    "        return 'up'\n",
    "    if state in [(1,2),(1,3),(2,3),(3,1),(4,1)]:\n",
    "        return 'right'\n",
    "    if state in [(2,1),(3,3),(4,3),(4,4)]:\n",
    "        return  'left'\n",
    "    if state in [(2,2)]:\n",
    "        return 'down'\n",
    "    if state in [(3,2)]:\n",
    "        return 'stop'\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    x, y = state\n",
    "    if action == 'up':\n",
    "        return (max(x-1, 0), y)\n",
    "    elif action == 'down':\n",
    "        return (min(x+1, grid_size-1), y)\n",
    "    elif action == 'left':\n",
    "        return (x, max(y-1, 0))\n",
    "    elif action == 'right':\n",
    "        return (x, min(y+1, grid_size-1))\n",
    "    elif action == 'stop':\n",
    "        return (x, y)\n",
    "\n",
    "# Policy evaluation using value iteration\n",
    "delta = 1\n",
    "theta = 1e-4\n",
    "\n",
    "while delta > theta:\n",
    "    delta = 0\n",
    "    for x in range(grid_size):\n",
    "        for y in range(grid_size):\n",
    "            v = V[x, y]\n",
    "            action = policy((x, y))\n",
    "            next_state = get_next_state((x, y), action)\n",
    "            x_n, y_n = next_state\n",
    "            new_v = R[x_n, y_n] + gamma * V[next_state]  # 这里R理论上应该和s a s‘都有关 简化起见 只是给了固定值\n",
    "            V_new[x, y] = new_v\n",
    "            delta = max(delta, abs(v - new_v))\n",
    "    V = V_new\n",
    "\n",
    "print(\"Value function:\")\n",
    "print(np.round(V, decimals=1)) # bad policy就要重写reward了 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T02:05:40.268228100Z",
     "start_time": "2024-07-19T02:05:40.257781600Z"
    }
   },
   "id": "2fbad97bd390e691"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9970bcd6d383ea25"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      "[[ 5.8  5.6  6.2  6.5  5.8]\n",
      " [ 6.5  7.2  8.   7.2  6.5]\n",
      " [ 7.2  8.  10.   8.   7.2]\n",
      " [ 8.  10.  10.  10.   8. ]\n",
      " [ 7.2  9.  10.   9.   8.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define a upgradeable policy\n",
    "class Policy:\n",
    "    def __init__(self, grid_size):\n",
    "        # 0 ↑       1 →         2 ↓         3 ←         4: stop\n",
    "        self.policy = {}\n",
    "        # for x in range(grid_size): # 无需初始化策略 但gamma降低到0的话 需要随机初始化 否则有几个点没有策略了\n",
    "        #     for y in range(grid_size):\n",
    "        #         self.policy.update({(x, y): random.randint(0,4)})\n",
    "    \n",
    "    def upgrade(self, x, y, action):\n",
    "        self.policy[x, y] = action\n",
    "\n",
    "class Reward:\n",
    "    def __init__(self, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "        self.R = np.zeros((grid_size, grid_size))\n",
    "        # Terminal states\n",
    "        self.R[3, 2] = 1\n",
    "        # Forbidden states\n",
    "        self.R[1, 1] = self.R[1, 2] = self.R[2, 2] = self.R[3, 1] = self.R[3, 3] = self.R[4, 1] = -1\n",
    "        # Boundary action\n",
    "    def __call__(self, state, action, next_state):\n",
    "        x, y = state\n",
    "        x_n, y_n = next_state\n",
    "        if x == 0 and action == 0:\n",
    "            return -1 # 最上面往上走\n",
    "        elif x == self.grid_size-1 and action == 2:\n",
    "            return -1 # 最下面往下走\n",
    "        elif y == 0 and action == 3:\n",
    "            return  -1 # 最左边往左走\n",
    "        elif y == self.grid_size-1 and action == 1:\n",
    "            return  -1 # 最右边往右走\n",
    "        elif (x == 0 and y == 0 and action == 3) \\\n",
    "                or (x == 0 and y == self.grid_size-1 and action == 1) \\\n",
    "                or (x == self.grid_size-1 and y == 0 and action == 3) \\\n",
    "                or (x == self.grid_size-1 and y == self.grid_size-1 and action == 1):\n",
    "            return -1\n",
    "        else:\n",
    "            return self.R[x_n, y_n]\n",
    "\n",
    "def get_next_state(state, action, grid_size):\n",
    "    x, y = state\n",
    "    if action == 0:\n",
    "        return (max(x-1, 0), y)\n",
    "    elif action == 1:\n",
    "        return (x, min(y+1, grid_size-1))\n",
    "    elif action == 2:\n",
    "        return (min(x+1, grid_size-1), y)\n",
    "    elif action == 3:\n",
    "        return (x, max(y-1, 0))\n",
    "    elif action == 4:\n",
    "        return (x, y)\n",
    "\n",
    "# Grid world size\n",
    "grid_size = 5\n",
    "# Initialize value function\n",
    "V = np.zeros((grid_size, grid_size))\n",
    "V_new = np.zeros_like(V)\n",
    "# Discount factor\n",
    "gamma = 0.9\n",
    "# Policy evaluation using value iteration\n",
    "delta = 1\n",
    "theta = 1e-9\n",
    "policy = Policy(grid_size)\n",
    "R = Reward(grid_size)\n",
    "\n",
    "while delta > theta:\n",
    "    delta = 0\n",
    "    for x in range(grid_size):\n",
    "        for y in range(grid_size):\n",
    "            v = V[x, y]\n",
    "            max_v = 0\n",
    "            for action in range(0,5): # 遍历所有策略 换句话说 策略固定 action value 就是 state value\n",
    "                next_state = get_next_state((x, y), action, grid_size)\n",
    "                new_v = R((x, y), action, next_state) + gamma * V[next_state]\n",
    "                if new_v > max_v: \n",
    "                    policy.upgrade(x, y, action)\n",
    "                    max_v = new_v\n",
    "            V_new[x, y] = max_v\n",
    "            delta = max(delta, abs(v - max_v))\n",
    "    V = V_new\n",
    "\n",
    "print(\"Value function:\")\n",
    "print(np.round(V, decimals=1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T06:00:57.030717500Z",
     "start_time": "2024-07-22T06:00:57.001397600Z"
    }
   },
   "id": "1aea07b35416cd7e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb17866b9b49215"
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面的算法又叫 Value iteration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e5d551e719487fc"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T08:27:54.554387700Z",
     "start_time": "2024-07-19T08:27:54.539439500Z"
    }
   },
   "id": "ff573f0f46af85a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7c787c4a2b2e9940"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
